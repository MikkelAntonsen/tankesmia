The authors explain how CNNs can learn to use the absolute position of objects in an image as a feature.
This is surprising because you would naively think that CNNs are translation equivariant or translation invariant (combined with a max-pool operation).

### Boundary effect
The authors claim that CNNs can encode absolute position using boundary effects.
Boundary effects exists because "images have finite support for convolutions" (convolutions can't be applied to the border of an image without padding). And padding creates boundary effect how __???__

### Classification toy example
The authors demonstrate that a network (1 layer, 5x5, 0-padding, same-conv, relu, max-pool, SGD, softmax) is able to use aboslute position to classify objects by creating a dataset with two classes. The two classes look identical, but appear in different quadrants of an image. The only way the network can learn to classify them correctly is by knowing their absolute position in the image. The network is  able to classify them correctly.

Critisism: In [[#Classification toy example]] The author do not do a proper ablation to show that removing boundary effects removes the network's ability to solve the problem correctly.

### Relevant work
This paper is relevant to other work in that:
- replacing fully connceted layers with fully convolutional networks + global pooling do not necessarily make networks translation invariant.
- if you crop an image in latent space (like r-cnn) the representation can contain information about absolute position
- it shows that you can lose translation equivariance because of boundary effects
- it shows how stronger inductive priors (actual translation invariance/equivariance) gives higher data efficiency


### Boundary effect

Count the number of times any element of the input is part of the input to a convolutional kernel. 
If you look at valid-conv, same-conv, full-conv with no padding/zero-padding, the first elements do not sum to 2k+1 (where k is kernel size). This is the boundary effect.
Adding circular padding to same-conv and and full-conv removes boundary effect, but in a trade off with semantic effects.

Question: How do you go from uneven application to boundary effects?

##### Trade-offer
I receive boundary effects and worse inductive priors

You receive no semantic bi-effects (object being detected on the wrong side of the image)


### Follow up queue
- [ ] Md Amirul Islam, Sen Jia, and Neil DB Bruce. How much position information do convolutional neural networks encode? In ICLR, 2019
- [ ] 

[Source](https://arxiv.org/pdf/2003.07064.pdf)